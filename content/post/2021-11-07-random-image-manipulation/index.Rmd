---
title: Random Manipulation of a Random SmugMug Image
author: Tim Wilson
date: '2021-11-07'
slug: random-image-manipulation
categories:
  - R
tags:
  - Github Actions
  - SmugMug
  - Twitter
  - ImageMagick
---

This is a process that runs daily and applies a **random number of transformations** in a **random order** with **random settings** to a **randomly selected image** from my [SmugMug site](https://twilson.smugmug.com/). You can see a [list of the results](/image-randomize/) that are currently available. I started to try to do the math as to the number of possible outcomes and...it's beyond me.

High-level, this is what happens:

![](images/image-randomizer-flowchart.png "Image Randomizer Flowchart"){width=700px}

Read on for details!

## The Motivation

I don't think this project qualifies as generative art (or generative "aRt," specifically, but if you're interested in that sort of thing, check out [Danielle Navarro's amazing work](https://art.djnavarro.net/) or [Claus O. Wilke's work](https://clauswilke.com/art/)—including his [NFTs](https://objkt.com/profile/clauswilke/created?search=&sortBy=askAsc)!—or [Koen Derks's aRtsy package that is specifically ggplot-oriented](https://koenderks.github.io/aRtsy/)). 

Rather, it was an opportunity for me to combine a couple of my hobbies—[nature photography](https://twilson.smugmug.com/) and R—into a single project and learn along the way! When it comes to doing programmatic (machine?) manipulation of photos, this is nothing nearly as involved as the neural networks employed by [Deep Dream Generator](https://deepdreamgenerator.com/), but, hey, this is me combined with Starry Night in an AI's dream:

![](images/tim_wilson_starry_night.jpeg "Tim Wilson Dreamt of with Starry Night"){width=400px}

The learning that came along with the effort was:

* **Cloud-based automation:** I initially thought this would be Docker and the Google Cloud Platform, but, ultimately, it wound up just being GitHub Actions, which turned out to be cheaper and, arguably, simpler.
* **Using APIs without a platform-specific package:** I've known that [`httr`](https://httr.r-lib.org/) is the go-to package for working with REST APIs, but I had never used it directly from authentication through actual GETs. 
* **Image manipulation:** Raster-based images are, at their core, just matrices with each pixel being represented by a value in the matrix. It turns out that it's fun to think about exactly what the underlying matrix manipulation is that adds different effects to an image.
* **Static site generation:** This wound up being [Hugo](https://gohugo.io/) along with [Netlify](https://www.netlify.com/) (with GitHub along the way).

Somewhere in all of that, I got to work with [GitHub Secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets) to securely store API tokens for SmugMug and Twitter!

Below, I've broken down the different components of the work, linking to specific resources for additional details. But, the full set of code really comes down to:

* A [folder in the GitHub repository that serves this site](https://github.com/gilliganondata/gilliganondata_site/tree/main/content/image-randomize) (`master.R` is really the key file; it sources all the other files)
* The [GitHub Action workflow YAML](https://github.com/gilliganondata/gilliganondata_site/blob/main/.github/workflows/daily-image-run.yaml) that is also part of the repository that serves this site

We can dig in a little deeper to explain the what's what there.

## Pulling a Random Image from SmugMug

As of this writing, there is not yet a package built specifically for connecting to SmugMug, so I worked through their pretty comprehensive [API documentation](https://api.smugmug.com/api/v2/doc) and then used the [`httr`](https://httr.r-lib.org/) to actually query the API.

Although I was only pulling public images (from [my personal SmugMug site](https://twilson.smugmug.com/), using the API still requires creating and using an API token (specifically, a key and a secret). While doing the initial development, I simply put these in my `.Renviron` file as `SMUGMUG_KEY` and `SMUGMUG_SECRET` and then accessed them using `Sys.getenv()`. When I shifted to running the script via a GitHub Actions workflow, I simply created [GitHub Secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets) with the exact same name. And...it worked! I was expecting that I was going to need to update the R script to actually access those values differently when they were set as GitHub Secrets, but, nope! As the workflow ran and established an environment, those values were there and were accessible with the exact same code.

_Side note: Ultimately, the R script itself is something I can run locally and make **no** changes to when I check it in for use in the GitHub Actions workflow. The **only** "not needed for local but needed for the workflow run" is an `options()` setting for blogdown. This is one line in `master.R` and causes no harm whatsoever when running locally. Overall, I was pretty tickled that this is how things worked out._

What I wanted from SmugMug was pretty simple: a data frame that lists every image on my site.

What it took to do that was a two-step process:

1. Pull all of the _albums_ on the site
2. Go through each album and pull each image in the album

I accomplished this with a little bit of recursion. The code is pretty straightforward and contained in the [init_get_list_of_images.R](https://github.com/gilliganondata/gilliganondata_site/blob/main/content/image-randomize/init_get_list_of_images.R) script.

The result was a data frame with one row for each image on the site. So, then it was just a matter of picking a row at random from that data frame using `sample()` and then tracking down the actual URL for that image and download and save it. I wound up capping the max width of the images to work with at 4,096 pixels just for file size and consistency reasons (since I record the exact transformations performed, it would be reasonably easy to recreate the same effect with a larger file if I wanted to).

This was actually a little messier than I expected, so it got its own script called [init_get_random_image.R](https://github.com/gilliganondata/gilliganondata_site/blob/main/content/image-randomize/init_get_random_image.R) to perform that work.

Now it's time to apply some transformations.

## Creating and Applying a Random Set of Transformations

I set this up to be reasonably extensible, in that it is modular with one script file for each possible transformation. Most of the transformations were ones available in Jeroen Ooms's [`magick` package](https://cran.r-project.org/web/packages/magick/vignettes/intro.html), which is a wrapper for [ImageMagick STL](https://www.imagemagick.org/Magick++/STL.html). But, I also have a soft spot for Hiroyuki Tsuda's [`sketcher` package](https://htsuda.net/sketcher/), as that was the first package I used to do any image manipulation, so I included `sketch` as one of the transformations, too.

The _possible_ transformations that I've included so far are (each is in it's own `.R` file):

* [magick] [**Modulate**](https://github.com/gilliganondata/gilliganondata_site/blob/main/content/image-randomize/mgk_image_modulate.R)—this adjusts the hue, saturation, and brightness of the image. The image starts with each of these three values as "100," and then the script randomly selects values between 50 and 150 to apply to the transformation
* [magick] [**Median**](https://github.com/gilliganondata/gilliganondata_site/blob/main/content/image-randomize/mgk_image_median.R)—this is an interesting one. The only input is a "radius" value, which I use a random value between 15 and 50. Then, for _each_ pixel in the image, the transformation looks at _all_ of the pixels within that radius of the pixel and changes that pixel's color to be the median color of all of those pixels. This winds up _mostly_ blurring the image...except not quite. If there is a very hard, high contrast edge, that tends to stick around (it's median and not mean!). This is one of the more time-consuming transformations, which makes sense.
* [magick] [**Colorize**](https://github.com/gilliganondata/gilliganondata_site/blob/main/content/image-randomize/mgk_image_colorize.R)—this takes a color (which I randomly set by choosing random R, G, and B values) and an opacity and overlays that on the image. It, essentially, tints the image with a random color and to a random degree.
* [magick] [**Quantize**](https://github.com/gilliganondata/gilliganondata_site/blob/main/content/image-randomize/mgk_image_quantize.R)—this reduces the image to a limited number of total colors, which I've set to be somewhere between 4 and 16. In some cases, earlier transformations will have already converted the image to be grayscale and this has no actual effect. In other cases, it does!
* [magick] [**Sketch**](https://github.com/gilliganondata/gilliganondata_site/blob/main/content/image-randomize/skc_sketch.R)—this is another somewhat process-intensive operation that makes a "sketch" of the image. The settings for it are the overall style (1 or 2), the lineweight (1 to 6), the contrast level (10 to 60), the amount of shadow (a real number between 0 and 1), and the gain (a real number between 0 and 1)

The scripts for each of the above do a few things:

* Select random values to be used for the settings
* Apply the transformation to the current version of the image and then update that as the current version
* Add to a string that records the specific settings that were used

The question remains: what transformations are applied and in what order? This is simply a case where there is a tibble with the paths to each of these transformation scripts in the `master.R` script. The script:

1. Shuffles the order of the rows in the tibble.
2. Selects a random number between 1 and the number of rows in that tibble.
3. Pulls that number of rows from the tibble.
4. Runs the scripts (the paths) that were pulled.

I think it's actually pretty elegant. All that is required for me to add another transformation is to create a new file for that transformation and add the path to that file to the original tibble.

## Creating a Web Page with the Before/After


## Tweeting the Result


## Automating All of This


We'll get to writing out the details later, but this is really about making a few different things work together to see what happens:

-   Pulling an image from a SmugMug site at random (via the SmugMug API)
-   Applying a random number of manipulations in a random order with random settings to that image
-   Publishing the before and after as a new web page on this site
-   Adding a link to that page to a master web page listing links to all of the times it's been run
-   Tweeting the before/after in a single tweet and linking back to that web page
-   Doing the above on a daily basis via Github actions
